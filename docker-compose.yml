version: '3.6'

services:
  chatbot:
    container_name: chatbot
    image: chatbot:latest
    restart: unless-stopped
    build: .
    ports:
      - 80:3000
    environment:
      - 'DEFAULT_MODEL=llama3.2:3b'
      - 'OLLAMA_HOST=http://louis-llm.waftest.weborion.net'
      
  llama-server:
    container_name: llama-server
    image: llama-server:latest
    restart: unless-stopped
    build:
      context: ./llama-server
    ports:
      - 11434:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0'
  

  llama-server-test:
    container_name: llama-server-test
    image: llama-server-test:latest
    restart: unless-stopped
    build:
      context: ./llama-server
    ports:
      - 11432:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0'